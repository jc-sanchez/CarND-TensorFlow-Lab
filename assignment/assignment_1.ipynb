{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Assignment 1 - TensorFlow Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this assignment, we'll use all the tools we learned from Lesson 1 to run a neural network in TensorFlow.  The neural network will be classifying the letters A-J from different images.  These images are one of the letters A-J in a different font, as show in the above image.  At the end of this assignment, you'll be making predictions with at least an 80% accuracy!  Let's jump right in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this assignment, we first need to import all the necessary modules.  Run the code below.  It will print \"All modules imported.\" after it has imported all the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST data is a large dataset to handle for most computers.  It contains 500 thousands images for just training.  We'll be using a subset of this data, 21,000 images for each class(A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downlading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# ToDo: Add URL\n",
    "# Download the training and test dataset\n",
    "download('', 'notMNIST_train.zip')\n",
    "download('', 'notMNIST_test.zip')\n",
    "\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210001/210001 [00:35<00:00, 5946.34files/s]\n",
      "100%|██████████| 10001/10001 [00:01<00:00, 6405.48files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from zip file\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/mean_variance.png\" style=\"height: 75%;width: 75%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for our training and test data.  To normalize the data, you need to implement the <i>normalize()</i> function to apply zero mean and zero variance scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features\n",
    "# Apply zero mean and zero variance scale to the image features\n",
    "def normalize(data):\n",
    "    #  ToDo: Problem 1 - Implement function to normalize data\n",
    "\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])),\n",
    "    np.array([-0.4, -0.3, -0.2, -0.099, 0.0, 0.099, 0.199, 0.3, 0.4, 0.5]),\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize(np.array([-100, -30, -1000, -20, -20, -10, -10, -20, -10, -10])),\n",
    "    np.array([9.5, 2.5, 99.5, 1.5, 1.5, 0.5, 0.5, 1.5, 0.5, 0.5]))\n",
    "\n",
    "train_features = normalize(train_features)\n",
    "test_features = normalize(test_features)\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_labels)\n",
    "train_labels = encoder.transform(train_labels)\n",
    "test_labels = encoder.transform(test_labels)\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Talk about how to refresh the data if a mistake was made **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels loaded.\n",
      "Number of training smaples: 10000\n",
      "Feature data type: float32\n",
      "Feature data type: float32\n",
      "Feature data type: float32\n",
      "Label data type: int64\n",
      "Number of features: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memoy\n",
    "\n",
    "# Limit the amount of training data to use in the neural network.\n",
    "# Using all the training data will take too long to process.\n",
    "train_subset = 10000\n",
    "if len(train_features)> train_subset:\n",
    "    train_features = train_features[:train_subset, :]\n",
    "    train_labels = train_labels[:train_subset, :]\n",
    "\n",
    "print('Features and labels loaded.')\n",
    "print('Number of training smaples: {}'.format(len(train_features)))\n",
    "print('Feature data type: {}'.format(train_features.dtype))\n",
    "print('Label data type: {}'.format(train_labels.dtype))\n",
    "print('Number of features: {}'.format(train_features.shape[1]))\n",
    "print('Number of classes: {}'.format(train_labels.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "For the neural network to train on our data, we need two tensors for input.  One tensor for the features and the other tensor for labels.\n",
    "** EDIT CODE ** ** Give them information on what shape the data is in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 2 - Set the features and labels tensor\n",
    "features = ???\n",
    "labels = ???\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "# Don't modify the feed dicts\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Let's do that same for weights and biases.  Set one tensor for weights and one tensor for biases.\n",
    "** EDIT CODE ** ** Give them information on what shape the data is in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 3 - Set the weights and biases tensors\n",
    "weights = ???\n",
    "biases = ???\n",
    "\n",
    "# Linear Regression Function WX + b\n",
    "# Don't Modify the function\n",
    "logits = tf.matmul(features, weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "** CONTINUE: The code below isn't working. **\n",
    "** EDIT CODE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CONTINUE: Talk about how we calculate accuracty **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/learn_rate_tune.png\" style=\"height: 75%;width: 75%\">\n",
    "## Problem 5\n",
    "Tweak the learning rate and number of steps to get a good accuracy. ** CONTINUE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:25<00:00, 31.38steps/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b1966a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice Job! Test Accuracy is 0.828000009059906\n"
     ]
    }
   ],
   "source": [
    "# Problem 5 - Tune the learning rate and number of steps to get a good accuracy\n",
    "learning_rate = 1\n",
    "num_steps = 10\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "test_accuracy = 0.0\n",
    "steps = []\n",
    "loss_steps = []\n",
    "train_acc_steps = []\n",
    "valid_acc_steps = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    # Progress bar\n",
    "    steps_pbar = tqdm(range(num_steps), unit='steps')\n",
    "    # The training cycle\n",
    "    for step in steps_pbar:\n",
    "        # Run optimizer and get loss\n",
    "        _, l = session.run(\n",
    "            [optimizer, loss],\n",
    "            feed_dict=train_feed_dict)\n",
    "        \n",
    "        # Log every 50 steps\n",
    "        if not step % 50:\n",
    "            # Calculate Training and Validation accuracy\n",
    "            training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "            validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "            # Log steps\n",
    "            steps.append(step)\n",
    "            loss_steps.append(l)\n",
    "            train_acc_steps.append(training_accuracy)\n",
    "            valid_acc_steps.append(validation_accuracy)\n",
    "\n",
    "    # Check accuracy against Test data\n",
    "    test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(steps, loss_steps, 'g')\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(steps, train_acc_steps, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(steps, valid_acc_steps, 'b', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greate than 0.80'.format(test_accuracy)\n",
    "\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
